{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "import cv2\n",
    "import csv\n",
    "import PIL\n",
    "\n",
    "Dataset_Path = os.path.join(os.getcwd(),'inaturalist_12K')\n",
    "# Dataset_Path = '/content/drive/MyDrive/inaturalist_12K'\n",
    "train_path = os.path.join(Dataset_Path , 'train')\n",
    "test_path = os.path.join(Dataset_Path , 'val')\n",
    "# test_path1 = test_path\n",
    "import pathlib\n",
    "Dataset_Path = pathlib.Path(Dataset_Path)\n",
    "train_path = pathlib.Path(train_path)\n",
    "test_path = pathlib.Path(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.test.gpu_device_name()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "                                                            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5500)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "IMAGE_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 files belonging to 10 classes.\n",
      "Using 9000 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_path, \n",
    "    class_names=None, \n",
    "    color_mode='rgb', \n",
    "    batch_size=batch_size, \n",
    "    image_size=(IMAGE_SIZE,IMAGE_SIZE), \n",
    "    shuffle=True, \n",
    "    seed=1234, \n",
    "    validation_split=0.1,\n",
    "    subset=\"training\",\n",
    "    interpolation='bilinear'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9999 files belonging to 10 classes.\n",
      "Using 999 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_path, \n",
    "    class_names=None, \n",
    "    color_mode='rgb', \n",
    "    batch_size=batch_size, \n",
    "    image_size=(IMAGE_SIZE,IMAGE_SIZE), \n",
    "    shuffle=True, \n",
    "    seed=1234, \n",
    "    validation_split=0.1,\n",
    "    subset=\"validation\",\n",
    "    interpolation='bilinear'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_path, \n",
    "    class_names=None, \n",
    "    color_mode='rgb', \n",
    "    batch_size=batch_size, \n",
    "    image_size=(IMAGE_SIZE,IMAGE_SIZE), \n",
    "    shuffle=True,\n",
    "    seed=1234,\n",
    "    interpolation='bilinear'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Activation, MaxPooling2D, Dropout , BatchNormalization, experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = Sequential(\n",
    "  [\n",
    "    experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "                                                 input_shape=(IMAGE_SIZE, \n",
    "                                                              IMAGE_SIZE,\n",
    "                                                              3)),\n",
    "    experimental.preprocessing.RandomRotation(0.2),\n",
    "    experimental.preprocessing.RandomZoom(0.2),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model(model_name, epochs=10):\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    prediction_layer = tf.keras.layers.Dense(10,activation='softmax')\n",
    "    inputs = tf.keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    if model_name == 'InceptionV3':\n",
    "        base_model = tf.keras.applications.InceptionV3(input_shape=(IMAGE_SIZE,IMAGE_SIZE,3), include_top=False, weights='imagenet')\n",
    "        x = tf.keras.applications.imagenet_utils.preprocess_input(x,mode='tf')\n",
    "    elif model_name == 'InceptionResNetV2':\n",
    "        base_model = tf.keras.applications.InceptionResNetV2(input_shape=(IMAGE_SIZE,IMAGE_SIZE,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "        x = tf.keras.applications.imagenet_utils.preprocess_input(x,mode='tf')\n",
    "    elif model_name == 'ResNet50':\n",
    "        base_model = tf.keras.applications.ResNet50(input_shape=(IMAGE_SIZE,IMAGE_SIZE,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "        x = tf.keras.applications.imagenet_utils.preprocess_input(x,mode='caffe')\n",
    "    elif model_name == 'Xception':\n",
    "        base_model = tf.keras.applications.Xception(input_shape=(IMAGE_SIZE,IMAGE_SIZE,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "        x = tf.keras.applications.imagenet_utils.preprocess_input(x,mode='tf')\n",
    "    else:\n",
    "        base_model = None\n",
    "        preprocess_input = None\n",
    "    base_model.trainable = False\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "    initial_epochs = epochs\n",
    "    history = model.fit(train_ds,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=val_ds,\n",
    "                       callbacks=[WandbCallback()])\n",
    "#     model.save('PartB_models' + os.sep + 'base_models' + os.sep + model_name)\n",
    "#     model.save('PartB_models' + os.sep + 'models' + os.sep + model_name)\n",
    "    return model,history,base_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_name in ['InceptionV3','InceptionResNetV2','ResNet50','Xception']:\n",
    "#     save_pretrained_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_saved_pretrained_model(model_name, epochs=10):\n",
    "#     base_model = tf.keras.models.load_model('PartB_models' + os.sep + 'base_models' + os.sep + model_name)\n",
    "#     model = tf.keras.models.load_model('PartB_models' + os.sep + 'models' + os.sep + model_name)\n",
    "#     return base_model, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_pretrain_conv_model('InceptionV3',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: mooizz (use `wandb login --relogin` to force relogin)\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Jaitesh/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"866040d7d81f67025d43e7d50ecd83d54b6cf977\", relogin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid', #grid, random\n",
    "    'metric': {\n",
    "      'name': 'val_accuracy',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'epochs':{\n",
    "            'values': [10]\n",
    "        },\n",
    "        'model_name': {  \n",
    "            'values': [\"InceptionResNetV2\"]#['InceptionV3','InceptionResNetV2','ResNet50','Xception']\n",
    "        },\n",
    "        'strategy':{\n",
    "            'values': [4]#[1,2,3]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: asuph1kb\n",
      "Sweep URL: https://wandb.ai/mooizz/conv_inaturalist/sweeps/asuph1kb\n"
     ]
    }
   ],
   "source": [
    "from wandb.keras import WandbCallback\n",
    "sweep_id = wandb.sweep(sweep_config, entity=\"mooizz\",project=\"conv_inaturalist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune():\n",
    "    config_defaults = {\n",
    "        'epochs' : 10,\n",
    "        'model_name': 'InceptionV3',\n",
    "        'strategy': '1'\n",
    "    }\n",
    "    wandb.init(config=config_defaults)\n",
    "    config = wandb.config\n",
    "    model, history, base_model = get_pretrained_model(config.model_name,config.epochs)\n",
    "    print(\"Number of layers in base Model: \", len(base_model.layers))\n",
    "    n = len(base_model.layers)\n",
    "    l = base_model.layers\n",
    "    fine_tune_at = n\n",
    "    base_model.trainable = True\n",
    "#     if config.strategy == 0:\n",
    "#         fine_tune_at = n\n",
    "    if config.strategy == 1:\n",
    "        fine_tune_at = n-1\n",
    "    if config.strategy == 2:\n",
    "        fine_tune_at = n-10\n",
    "    if config.strategy == 3:\n",
    "        fine_tune_at = n-50\n",
    "    if config.strategy == 4:\n",
    "        fine_tune_at = n-80\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable =  False   \n",
    "    print(len(model.trainable_variables))\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.00001),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    total_epochs = 2*config.epochs\n",
    "    \n",
    "    history_fine = model.fit(train_ds,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=val_ds,\n",
    "                            callbacks=[WandbCallback()])\n",
    "    model.save('models'+os.sep+str(sweep_id)+os.sep+wandb.run.name)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 25s 414ms/step - loss: 0.4565 - accuracy: 0.8460\n",
      "32/32 [==============================] - 9s 178ms/step - loss: 0.5297 - accuracy: 0.8175\n",
      "32/32 [==============================] - 11s 198ms/step - loss: 0.5368 - accuracy: 0.8230\n",
      "32/32 [==============================] - 8s 155ms/step - loss: 0.7097 - accuracy: 0.8160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7096725106239319, 0.8159999847412109]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model1 = tf.keras.models.load_model('models'+os.sep+str('1f8m104a')+os.sep+'worthy-sweep-6')\n",
    "best_model1.evaluate(test_ds)\n",
    "best_model2 = tf.keras.models.load_model('models'+os.sep+str('1f8m104a')+os.sep+'kind-sweep-12')\n",
    "best_model2.evaluate(test_ds)\n",
    "best_model3 = tf.keras.models.load_model('models'+os.sep+str('1f8m104a')+os.sep+'robust-sweep-3')\n",
    "best_model3.evaluate(test_ds)\n",
    "best_model4 = tf.keras.models.load_model('models'+os.sep+str('1f8m104a')+os.sep+'upbeat-sweep-9')\n",
    "best_model4.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(config=config_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_id = wandb.sweep(sweep_config, entity=\"mooizz\",project=\"conv_inaturalist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: du4ry92t with config:\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tmodel_name: InceptionResNetV2\n",
      "wandb: \tstrategy: 4\n",
      "wandb: wandb version 0.10.26 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">radiant-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mooizz/conv_inaturalist\" target=\"_blank\">https://wandb.ai/mooizz/conv_inaturalist</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/mooizz/conv_inaturalist/sweeps/kk02e6eo\" target=\"_blank\">https://wandb.ai/mooizz/conv_inaturalist/sweeps/kk02e6eo</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/mooizz/conv_inaturalist/runs/du4ry92t\" target=\"_blank\">https://wandb.ai/mooizz/conv_inaturalist/runs/du4ry92t</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\ConvolutionalNetwork\\wandb\\run-20210415_112130-du4ry92t</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 [==============================] - 58s 331ms/step - loss: 2.2959 - accuracy: 0.2343 - val_loss: 1.4612 - val_accuracy: 0.6476\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 31s 222ms/step - loss: 1.4814 - accuracy: 0.5777 - val_loss: 1.0452 - val_accuracy: 0.7558\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 31s 223ms/step - loss: 1.1781 - accuracy: 0.6615 - val_loss: 0.8748 - val_accuracy: 0.7808\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 32s 224ms/step - loss: 1.0373 - accuracy: 0.6943 - val_loss: 0.7916 - val_accuracy: 0.7928\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 31s 223ms/step - loss: 0.9627 - accuracy: 0.7165 - val_loss: 0.7427 - val_accuracy: 0.7928\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 31s 217ms/step - loss: 0.9156 - accuracy: 0.7206 - val_loss: 0.7123 - val_accuracy: 0.7988\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 30s 213ms/step - loss: 0.8831 - accuracy: 0.7281 - val_loss: 0.6891 - val_accuracy: 0.8028\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 30s 211ms/step - loss: 0.8640 - accuracy: 0.7336 - val_loss: 0.6730 - val_accuracy: 0.8048\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 30s 210ms/step - loss: 0.8424 - accuracy: 0.7425 - val_loss: 0.6604 - val_accuracy: 0.8038\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 32s 228ms/step - loss: 0.8267 - accuracy: 0.7458 - val_loss: 0.6500 - val_accuracy: 0.8058\n",
      "Number of layers in base Model:  780\n",
      "52\n",
      "Epoch 10/20\n",
      "141/141 [==============================] - 45s 265ms/step - loss: 0.8042 - accuracy: 0.7415 - val_loss: 0.5657 - val_accuracy: 0.8138\n",
      "Epoch 11/20\n",
      "141/141 [==============================] - 30s 214ms/step - loss: 0.7367 - accuracy: 0.7578 - val_loss: 0.5370 - val_accuracy: 0.8208\n",
      "Epoch 12/20\n",
      "141/141 [==============================] - 32s 224ms/step - loss: 0.6687 - accuracy: 0.7748 - val_loss: 0.5241 - val_accuracy: 0.8288\n",
      "Epoch 13/20\n",
      "141/141 [==============================] - 33s 235ms/step - loss: 0.6468 - accuracy: 0.7806 - val_loss: 0.5126 - val_accuracy: 0.8368\n",
      "Epoch 14/20\n",
      "141/141 [==============================] - 32s 228ms/step - loss: 0.6250 - accuracy: 0.7945 - val_loss: 0.5040 - val_accuracy: 0.8408\n",
      "Epoch 15/20\n",
      "141/141 [==============================] - 36s 254ms/step - loss: 0.5862 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.8408\n",
      "Epoch 16/20\n",
      "141/141 [==============================] - 32s 228ms/step - loss: 0.5528 - accuracy: 0.8099 - val_loss: 0.4947 - val_accuracy: 0.8428\n",
      "Epoch 17/20\n",
      "141/141 [==============================] - 34s 243ms/step - loss: 0.5496 - accuracy: 0.8194 - val_loss: 0.4901 - val_accuracy: 0.8488\n",
      "Epoch 18/20\n",
      "141/141 [==============================] - 33s 236ms/step - loss: 0.5297 - accuracy: 0.8187 - val_loss: 0.4903 - val_accuracy: 0.8498\n",
      "Epoch 19/20\n",
      "141/141 [==============================] - 33s 233ms/step - loss: 0.5063 - accuracy: 0.8262 - val_loss: 0.4963 - val_accuracy: 0.8428\n",
      "Epoch 20/20\n",
      "141/141 [==============================] - 31s 220ms/step - loss: 0.4717 - accuracy: 0.8390 - val_loss: 0.4969 - val_accuracy: 0.8509\n",
      "INFO:tensorflow:Assets written to: models\\kk02e6eo\\radiant-sweep-1\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 41012<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 208.61MB of 208.61MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\ConvolutionalNetwork\\wandb\\run-20210415_112130-du4ry92t\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\ConvolutionalNetwork\\wandb\\run-20210415_112130-du4ry92t\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.4672</td></tr><tr><td>accuracy</td><td>0.84156</td></tr><tr><td>val_loss</td><td>0.49689</td></tr><tr><td>val_accuracy</td><td>0.85085</td></tr><tr><td>_runtime</td><td>726</td></tr><tr><td>_timestamp</td><td>1618466617</td></tr><tr><td>_step</td><td>20</td></tr><tr><td>best_val_loss</td><td>0.49007</td></tr><tr><td>best_epoch</td><td>16</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▅▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▆▆▆▆▆▆▆▇▇▇████████</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▆▆▆▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▆▆▆▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">radiant-sweep-1</strong>: <a href=\"https://wandb.ai/mooizz/conv_inaturalist/runs/du4ry92t\" target=\"_blank\">https://wandb.ai/mooizz/conv_inaturalist/runs/du4ry92t</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, finetune)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
